# -*- coding: utf-8 -*-
"""Naive_Bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H69RrKfdtT8sQb2TrFhh4HaH3V4WGeZa
"""

import numpy as np



class NaiveBayes():
    
  # implrement fit method  
  def fit(self, X, y):
    samples, features = X.shape #initiate number of samples(rows) and number of features(columns)
    self.classes = np.unique(y) #set unique classes
    classes = len(self.classes) #define number of classes as len of self.classes
    
    #initiate mean, var, priors
    self.mean = np.zeros((classes, features), dtype = np.float64)
    self.var = np.zeros((classes, features), dtype = np.float64)
    self.priors = np.zeros(classes, dtype = np.float64)
    
    #functions to calculate mean, var, priors
    for a in self.classes:
      X_a = X[a == y]
      self.mean[a,:] = X_a.mean(axis=0)
      self.var[a,:] = X_a.var(axis=0)
      self.priors[a] = X_a.shape[0] / float(samples)
  
  #implement predict method
  def predict(self, X):
    y_pred = [self.pred(x) for x in X]
    return y_pred
 
 #helper for predict method
  def pred(self, x):
    posteriors = []

    for index, b in enumerate(self.classes):
      prior = np.log(self.priors[index])
      class_conditional = np.sum(np.log(self.density_func(index, x)))
      posterior = class_conditional + prior 
      posteriors.append(posterior)

    return self.classes[np.argmax(posteriors)]
 
  #density function
  def density_func(self, class_idx, x):
    mean = self.mean[class_idx]
    var = self.var[class_idx]
    numerator = np.exp(- (x-mean)**2 / (2 * var))
    denominator = np.sqrt(2 * np.pi * var)
    return numerator / denominator

from sklearn.model_selection import train_test_split

#accuracy function
def accuracy(y_true, y_pred):
    accuracy = np.sum(y_true == y_pred) / len(y_true)
    return accuracy

#define the function Naive Bayes
nb = NaiveBayes()

#importing dataset
from google.colab import files
uploaded = files.upload()

#load dataset
import pandas as pd
shoppers = pd.read_csv('online_shoppers_intention.csv')
shoppers.head()

shoppers.describe()

shoppers.dtypes

#delete month and visitortype columns
shoppers.drop(['Month', 'VisitorType'], axis = 'columns', inplace = True)
shoppers.head()

#Change boolean values to 0 and 1
shoppers['Weekend'] = shoppers['Weekend'].astype(int)
shoppers['Revenue'] = shoppers['Revenue'].astype(int)

shoppers.head(20)

#Set target and feature columns
target = shoppers['Revenue']
feats = shoppers.drop('Revenue', axis='columns')

#Initiate test sets
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.2)

#Fit the algorithm
nb.fit(X_train, y_train)

#Generate score for the algorithm
predictions = nb.predict(y_test)

print("The accuracy of my Naive Bayes algorithm is", accuracy(y_test, predictions))

#Import the Naive bayes built-in model
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()

#fit the model
model.fit(X_train, y_train)

#Score of the model
model.score(X_test, y_test)

#Score comparison
print(f'Here is the result of my algorithm {accuracy(y_test, predictions)} and the library Naive Bayes GaussianNB {model.score(X_test, y_test)}')